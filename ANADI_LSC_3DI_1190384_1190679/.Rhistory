install.packages("gtable")
install.packages("tidyr")
install.packages("dplyr")
install.packages("moments")
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(moments)
install.packages("tidyr")
#Exercicio 1
#Import dos dados
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS1 <- read_csv("Dados excel/DADOS1.csv", skip = 2)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(moments)
#Exercicio 1
#Import dos dados
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS1 <- read_csv("Dados excel/DADOS1.csv", skip = 2)
colnames(DADOS1) <- c("Tempo_seg","ESP01","ESP01.1","ESP01.2","ESP01.3","ESP01.4","ESP01.5","ESP02"
,"ESP02.1","ESP02.2","ESP02.3","ESP02.4","ESP02.5","ESP03","ESP03.1",
"ESP03.2","ESP03.3","ESP03.4","ESP03.5","IC01","IC01.1","IC01.2","IC01.3",
"IC01.4","IC01.5","IC01.6","IC01.7","IC01.8","IC02","IC02.1","IC02.2",
"IC02.3","IC02.4","IC02.5","IC02.6","IC02.7","IC02.8")
DADOS1[DADOS1 == 0] <- NA
print(DADOS1)
View(DADOS1)
View(DADOS1)
#Alínea a)
#Adiciona uma coluna com o tempo em formato POSIXct
str(DADOS1$Tempo_seg)
segundos <- as.numeric(DADOS1$Tempo_seg)
DADOS1$Tempo <- as.POSIXct(segundos, tz = "GMT", origin = "1970-01-01")
# visualize os dados com a nova coluna de tempo
View(DADOS1)
#Alínea b)
data_selecionada <- subset(DADOS1,as.Date(DADOS1$Tempo) == as.Date("2013-08-04"))
temp_motores <- data_selecionada[, c("Tempo", "ESP01.3", "ESP02.3", "ESP03.3")]
temp_motores_final <- gather(temp_motores, key = "Bomba", value = "Temperatura", -Tempo)
ggplot(data = temp_motores_final, aes(x = Tempo, y = Temperatura, color = Bomba)) +
geom_line() +
labs(x = "Tempo", y = "Temperatura (K)", color = "Motor")
#Alínea c)
#Executar boxplot para todas as colunas de temperaturas do motor
boxplot(temp_motores$ESP01.3, temp_motores$ESP02.3, temp_motores$ESP03.3, main="Temperatura do motor nas bombas 1, 2 e 3 - 04/08/2013", ylab="Temperatura", xlab="Bomba")
axis(1, at = c(1:3), labels = c("ESP01.3", "ESP02.3","ESP03.3"))
#i)
#Criamos um novo dataframe apenas com os dados do mês de Março de 2014, com o auxílio da função
#filter:
df_filtered2 <- filter(DADOS1, as.Date(Tempo) >= as.Date("2014-03-01") & as.Date(Tempo) <= as.Date("2014-03-31"))
#Depois criamos uma lista para cada uma das bombas com o oil rate de cada bomba e depois a média
#de cada dia, usando a função substr com o intervalo [1,7] para captarmos a parte da data em que
#refere o ano e o mês:
df_filtered2oil1 <- as.numeric(DADOS1[substr(DADOS1$Tempo, 1, 7) == "2014-03", ]$IC01.8)
df_filtered2oil2 <- as.numeric(DADOS1[substr(DADOS1$Tempo, 1, 7) == "2014-03", ]$IC02.8)
media_bomba1 <- mean(na.omit(df_filtered2oil1))
media_bomba2 <- mean(na.omit(df_filtered2oil2))
#Cores para as barras do gráfico
cores <- c("red", "black")
# Criar o gráfico de barras com as cores personalizadas
bp <- barplot(c(media_bomba1, media_bomba2),
main = "Barris de petróleo produzidos diariamente",
ylab = "Média dos barris produzidos",
xlab = "Bomba",
col = cores,
legend.text = c("Bomba1", "Bomba2"))
# Adicionar o rótulo abaixo da primeira barra
text(bp[1], par("usr")[3] - 0.2, labels = "Bomba1", pos = 1)
# Adicionar o rótulo abaixo da segunda barra
text(bp[2], par("usr")[3] - 0.2, labels = "Bomba2", pos = 1)
# Seleciona o intervalo de tempo desejado (1-6-2013 e 31-5-2014)
intervalo_dados <- subset(DADOS1, as.Date(Tempo) >= as.Date("2013-06-01") & as.Date(Tempo) <= as.Date("2014-05-31") & IC01.8)
# Calcula quantidade petróleo de cada bomba por mês
quantidade_petroleo <- intervalo_dados %>%
mutate(Mes = format(as.Date(Tempo), "%Y-%m")) %>%
group_by(Mes) %>%
summarise(Barris = sum(`IC01.8`))
#Encontrar o mês em que a Bomba 1 extraiu mais barris de petróleo
mes_max <- quantidade_petroleo$Mes[which.max(quantidade_petroleo$Barris)]
#R:A bomba 1 extraiu mais barris de petróleo em março de 2014.
set.seed(300)
#Inicializaçao das listas
bomba1_daily_prod <- c()
bomba2_daily_prod <- c()
for(i in sample(1:365,10)){
#Em cada ciclo do loop as listas auxiliares dão reset
aux1 <- c()
aux2 <- c()
#Transforma o tempo que esta em segundos em dias (e.g. 1370044800s = dia 1) e compara para encontrar os dias da amostra aleatoria e depois faz a produção diaria nesse dia e guarda no vetor
aux1<-append(aux1, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$X)-1370044800)/86400+1) == i,]$IC01.8))
bomba1_daily_prod<-append(bomba1_daily_prod, mean(na.omit(aux1)))
aux2<-append(aux2, as.numeric(dados[as.integer((as.numeric(DADOS1$X)-1370044800)/86400+1) == i,]$IC02.8))
bomba2_daily_prod<-append(bomba2_daily_prod, mean(na.omit(aux2)))
}
#H0: μ1 <= μ2 (a média da produção diária de petróleo da bomba 1 é menor ou igual à média da produção diária de petróleo da bomba 2)
#H1: μ1 > μ2 (a média da produção diária de petróleo da bomba 1 é maior do que a média da produção diária de petróleo da bomba 2)
#nível de significância α = 0,05
# Teste de normalidade Shapiro-Wilk para verificar se as amostras seguem uma distribuição normal
shapiro.test(bomba1_daily_prod)
#H0: μ1 <= μ2 (a média da produção diária de petróleo da bomba 1 é menor ou igual à média da produção diária de petróleo da bomba 2)
#H1: μ1 > μ2 (a média da produção diária de petróleo da bomba 1 é maior do que a média da produção diária de petróleo da bomba 2)
#nível de significância α = 0,05
# Teste de normalidade Shapiro-Wilk para verificar se as amostras seguem uma distribuição normal
shapiro.test(bomba1_daily_prod)
#H0: μ1 <= μ2 (a média da produção diária de petróleo da bomba 1 é menor ou igual à média da produção diária de petróleo da bomba 2)
#H1: μ1 > μ2 (a média da produção diária de petróleo da bomba 1 é maior do que a média da produção diária de petróleo da bomba 2)
#nível de significância α = 0,05
# Teste de normalidade Shapiro-Wilk para verificar se as amostras seguem uma distribuição normal
shapiro.test(bomba1_daily_prod)
#filtrar dados entre periodo determinado para avaliar qual a media de produção diária na bomba 1 e 2
bomba1_oil_rate <- as.numeric(DADOS1[as.Date(DADOS1$Tempo) >= as.Date("2013-06-01") & as.Date(DADOS1$Tempo) <= as.Date("2014-05-31"), ]$IC01.8)
bomba2_oil_rate <- as.numeric(DADOS1[as.Date(DADOS1$Tempo) >= as.Date("2013-06-01") & as.Date(DADOS1$Tempo) <= as.Date("2014-05-31"), ]$IC02.8)
#verificar a alternativa para ver se se verifica
print(mean(na.omit(bomba1_oil_rate)))
print(mean(na.omit(bomba2_oil_rate)))
print(mean(na.omit(bomba1_oil_rate))>mean(na.omit(bomba2_oil_rate)))
#Podemos verificar que na "realidade" a hipótese alternativa está correta visto que a media de produçao diária da bomba 1 é maior do que a bomba 2 no mesmo intervalo de tempo
#iv.
#H0: μ1 <= μ2 (a média da produção diária de petróleo da bomba 1 é menor ou igual à média da produção diária de petróleo da bomba 2)
#H1: μ1 > μ2 (a média da produção diária de petróleo da bomba 1 é maior do que a média da produção diária de petróleo da bomba 2)
#nível de significância α = 0,05
# Teste de normalidade Shapiro-Wilk para verificar se as amostras seguem uma distribuição normal
shapiro.test(bomba1_daily_prod)
set.seed(300)
set.seed(300)
bomba1_daily_prod <- c()
bomba2_daily_prod <- c()
for(i in sample(1:365,10)){
#Em cada ciclo do loop as listas auxiliares dão reset
aux1 <- c()
aux2 <- c()
#Transforma o tempo que esta em segundos em dias (e.g. 1370044800s = dia 1) e compara para encontrar os dias da amostra aleatoria e depois faz a produção diaria nesse dia e guarda no vetor
aux1<-append(aux1, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$X)-1370044800)/86400+1) == i,]$IC01.8))
bomba1_daily_prod<-append(bomba1_daily_prod, mean(na.omit(aux1)))
aux2<-append(aux2, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$X)-1370044800)/86400+1) == i,]$IC02.8))
bomba2_daily_prod<-append(bomba2_daily_prod, mean(na.omit(aux2)))
}
dados <- read.csv("DADOS1.csv", sep =",")
#Cria dataframe com a produçao diaria das duas bombas
df_daily_prod<- list(bomba1_daily_prod, bomba2_daily_prod)
#Gera o boxplot com a funçao xaxt para suprimir a impressao de valores no eixo dos x
boxplot(df_daily_prod, xaxt = "n", main = "Produção diária")
#filtrar dados entre periodo determinado para avaliar qual a media de produção diária na bomba 1 e 2
bomba1_oil_rate <- as.numeric(DADOS1[as.Date(DADOS1$Tempo) >= as.Date("2013-06-01") & as.Date(DADOS1$Tempo) <= as.Date("2014-05-31"), ]$IC01.8)
bomba2_oil_rate <- as.numeric(DADOS1[as.Date(DADOS1$Tempo) >= as.Date("2013-06-01") & as.Date(DADOS1$Tempo) <= as.Date("2014-05-31"), ]$IC02.8)
#verificar a alternativa para ver se se verifica
print(mean(na.omit(bomba1_oil_rate)))
print(mean(na.omit(bomba2_oil_rate)))
print(mean(na.omit(bomba1_oil_rate))>mean(na.omit(bomba2_oil_rate)))
#Podemos verificar que na "realidade" a hipótese alternativa está correta visto que a media de produçao diária da bomba 1 é maior do que a bomba 2 no mesmo intervalo de tempo
for(i in sample(1:365,10)){
#Em cada ciclo do loop as listas auxiliares dão reset
aux1 <- c()
aux2 <- c()
#Transforma o tempo que esta em segundos em dias (e.g. 1370044800s = dia 1) e compara para encontrar os dias da amostra aleatoria e depois faz a produção diaria nesse dia e guarda no vetor
aux1<-append(aux1, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$X)-1370044800)/86400+1) == i,]$IC01.8))
bomba1_daily_prod<-append(bomba1_daily_prod, mean(na.omit(aux1)))
aux2<-append(aux2, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$X)-1370044800)/86400+1) == i,]$IC02.8))
bomba2_daily_prod<-append(bomba2_daily_prod, mean(na.omit(aux2)))
}
for(i in sample(1:365,10)){
#Em cada ciclo do loop as listas auxiliares dão reset
aux1 <- c()
aux2 <- c()
#Transforma o tempo que esta em segundos em dias (e.g. 1370044800s = dia 1) e compara para encontrar os dias da amostra aleatoria e depois faz a produção diaria nesse dia e guarda no vetor
aux1<-append(aux1, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$Tempo_seg)-1370044800)/86400+1) == i,]$IC01.8))
bomba1_daily_prod<-append(bomba1_daily_prod, mean(na.omit(aux1)))
aux2<-append(aux2, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$Tempo_seg)-1370044800)/86400+1) == i,]$IC02.8))
bomba2_daily_prod<-append(bomba2_daily_prod, mean(na.omit(aux2)))
}
#Cria dataframe com a produçao diaria das duas bombas
df_daily_prod<- list(bomba1_daily_prod, bomba2_daily_prod)
#Gera o boxplot com a funçao xaxt para suprimir a impressao de valores no eixo dos x
boxplot(df_daily_prod, xaxt = "n", main = "Produção diária")
axis(1, at = c(1, 2), labels = c("Bomba 1", "Bomba 2"))
#H0: μ1 <= μ2 (a média da produção diária de petróleo da bomba 1 é menor ou igual à média da produção diária de petróleo da bomba 2)
#H1: μ1 > μ2 (a média da produção diária de petróleo da bomba 1 é maior do que a média da produção diária de petróleo da bomba 2)
#nível de significância α = 0,05
# Teste de normalidade Shapiro-Wilk para verificar se as amostras seguem uma distribuição normal
shapiro.test(bomba1_daily_prod)
shapiro.test(bomba2_daily_prod)
#Como as amostras seguem uma distribuição normal (p-value > nivel de signiicancia)  podemos fazer um teste paramétrico e vamos usar o teste t
t.test(na.omit(bomba1_daily_prod), na.omit(bomba2_daily_prod), alternative="greater", conf.level = 0.95)
#Como o p-value é menor do que o nível de significância α = 0,05, rejeitamos a hipótese nula H0 e
#concluímos que há evidência estatística para suportar a hipótese alternativa H1.
#Ou seja, a média da produção diária de petróleo da bomba 1 é maior do que a média da bomba 2 no
#período de 1-6-2013 e 31-5-2014.
#Tratamento de dados
library(readr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS2 <- read_csv("Dados excel/DADOS2.csv")
View(DADOS2)
shapiro.test(DADOS2$SVM)
shapiro.test(DADOS2$DT)
shapiro.test(DADOS2$KN)
shapiro.test(DADOS2$RF)
shapiro.test(DADOS2$ML)
shapiro.test(DADOS2$GB)
#Como existe pelos menos um conjunto de dados com p-value < 0.05, o teste é não conclusivo,
#logo serão feitos testes com os coeficientes de Pearson e de Spearman
cor_matrix_pearson <- rcorr(as.matrix(data[3:8]), type = "pearson")
install.packages("Hmisc")
library(Hmisc)
#As correlações lineares positivas significativas (p-value < 0.05),
#são as seguintes: SVM-KN, SVM-GB, DT-RF, KN-GB. A correlação com maior valor (0.87) é a DT-RF.
cor_matrix_spearman <- rcorr(as.matrix(data[3:8]), type = "spearman")
#Como existe pelos menos um conjunto de dados com p-value < 0.05, o teste é não conclusivo,
#logo serão feitos testes com os coeficientes de Pearson e de Spearman
cor_matrix_pearson <- rcorr(as.matrix(data[3:8]), type = "pearson")
#Como existe pelos menos um conjunto de dados com p-value < 0.05, o teste é não conclusivo,
#logo serão feitos testes com os coeficientes de Pearson e de Spearman
cor_matrix_pearson <- rcorr(as.matrix(data[3:8]), type = "pearson")
library(readr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS2 <- read_csv("Dados excel/DADOS2.csv")
View(DADOS2)
#De seguida verificamos a normalidade da distribuição dos dados,
#onde H0: distribuição normal e H1: distribuição não normal.
#Como, n<30 são feitos testes de Shapiro
shapiro.test(DADOS2$SVM) # p-value = 0.2687
shapiro.test(DADOS2$DT)  # p-value = 0.06772
shapiro.test(DADOS2$KN)  # p-value = 0.6926
shapiro.test(DADOS2$RF)  # p-value = 0.3138
shapiro.test(DADOS2$ML)  # p-value = 0.02138
shapiro.test(DADOS2$GB)  # p-value = 0.5125
#Como existe pelos menos um conjunto de dados com p-value < 0.05, o teste é não conclusivo,
#logo serão feitos testes com os coeficientes de Pearson e de Spearman
cor_matrix_pearson <- rcorr(as.matrix(data[3:8]), type = "pearson")
cor_matrix_pearson <- rcorr(as.matrix(data[3:8]), type = "pearson")
#Como existe pelos menos um conjunto de dados com p-value < 0.05, o teste é não conclusivo,
#logo serão feitos testes com os coeficientes de Pearson e de Spearman
cor_matrix_pearson <- rcorr(as.matrix(DADOS2[3:8]), type = "pearson")
View(DADOS2)
View(cor_matrix_pearson)
#As correlações lineares positivas significativas (p-value < 0.05),
#são as seguintes: SVM-KN, SVM-GB, DT-RF, KN-GB. A correlação com maior valor (0.87) é a DT-RF.
cor_matrix_spearman <- rcorr(as.matrix(DADOS2[3:8]), type = "spearman
#As correlações lineares positivas significativas (p-value < 0.05),
#são as seguintes: SVM-KN, SVM-GB, DT-RF, KN-GB. A correlação com maior valor (0.87) é a DT-RF.
cor_matrix_spearman <- rcorr(as.matrix(DADOS2[3:8]), type = "spearman")
#As correlações lineares positivas significativas (p-value < 0.05),
#são as seguintes: SVM-KN, SVM-GB, DT-RF, KN-GB. A correlação com maior valor (0.87) é a DT-RF.
cor_matrix_spearman <- rcorr(as.matrix(DADOS2[3:8]), type = "spearman")
View(cor_matrix_pearson)
View(cor_matrix_pearson)
View(cor_matrix_spearman)
View(cor_matrix_spearman)
#As correlações lineares positivas significativas (p-value < 0.05),
#são as seguintes: SVM-KN, SVM-GB, DT-RF, KN-GB. A correlação com maior valor (0.87) é a DT-RF.
cor_matrix_spearman <- rcorr(as.matrix(DADOS2[3:8]), type = "spearman")
cor_matrix_pearson <- rcorr(as.matrix(DADOS2[3:8]), type = "pearson")
cor_matrix_pearson <- rcorr(as.matrix(DADOS2[3:8]), type = "pearson")
install.packages("readr")
install.packages("ggplot2")
install.packages("gtable")
install.packages("tidyr")
install.packages("dplyr")
install.packages("moments")
install.packages("Hmisc")
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(moments)
library(Hmisc)
install.packages("readr")
install.packages("Hmisc")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS1 <- read_csv("Dados excel/DADOS1.csv", skip = 2)
install.packages("readr")
install.packages("ggplot2")
install.packages("gtable")
install.packages("tidyr")
install.packages("dplyr")
install.packages("moments")
install.packages("Hmisc")
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(moments)
library(Hmisc)
library(reshape2)
library(car)
#Import dos dados
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS1 <- read_csv("Dados excel/DADOS1.csv", skip = 2)
colnames(DADOS1) <- c("Tempo_seg","ESP01","ESP01.1","ESP01.2","ESP01.3","ESP01.4","ESP01.5","ESP02"
,"ESP02.1","ESP02.2","ESP02.3","ESP02.4","ESP02.5","ESP03","ESP03.1",
"ESP03.2","ESP03.3","ESP03.4","ESP03.5","IC01","IC01.1","IC01.2","IC01.3",
"IC01.4","IC01.5","IC01.6","IC01.7","IC01.8","IC02","IC02.1","IC02.2",
"IC02.3","IC02.4","IC02.5","IC02.6","IC02.7","IC02.8")
DADOS1[DADOS1 == 0] <- NA
print(DADOS1)
#Adiciona uma coluna com o tempo em formato POSIXct
str(DADOS1$Tempo_seg)
segundos <- as.numeric(DADOS1$Tempo_seg)
DADOS1$Tempo <- as.POSIXct(segundos, tz = "GMT", origin = "1970-01-01")
# visualize os dados com a nova coluna de tempo
View(DADOS1)
data_selecionada <- subset(DADOS1,as.Date(DADOS1$Tempo) == as.Date("2013-08-04"))
temp_motores <- data_selecionada[, c("Tempo", "ESP01.3", "ESP02.3", "ESP03.3")]
temp_motores_final <- gather(temp_motores, key = "Bomba", value = "Temperatura", -Tempo)
ggplot(data = temp_motores_final, aes(x = Tempo, y = Temperatura, color = Bomba)) +
geom_line() +
labs(x = "Tempo", y = "Temperatura (K)", color = "Motor")
#Executar boxplot para todas as colunas de temperaturas do motor
boxplot(temp_motores$ESP01.3, temp_motores$ESP02.3, temp_motores$ESP03.3, main="Temperatura do motor nas bombas 1, 2 e 3 - 04/08/2013", ylab="Temperatura", xlab="Bomba")
axis(1, at = c(1:3), labels = c("ESP01.3", "ESP02.3","ESP03.3"))
#i)
#Criamos um novo dataframe apenas com os dados do mês de Março de 2014, com o auxílio da função
#filter:
df_filtered2 <- filter(DADOS1, as.Date(Tempo) >= as.Date("2014-03-01") & as.Date(Tempo) <= as.Date("2014-03-31"))
#Depois criamos uma lista para cada uma das bombas com o oil rate de cada bomba e depois a média
#de cada dia, usando a função substr com o intervalo [1,7] para captarmos a parte da data em que
#refere o ano e o mês:
df_filtered2oil1 <- as.numeric(DADOS1[substr(DADOS1$Tempo, 1, 7) == "2014-03", ]$IC01.8)
df_filtered2oil2 <- as.numeric(DADOS1[substr(DADOS1$Tempo, 1, 7) == "2014-03", ]$IC02.8)
media_bomba1 <- mean(na.omit(df_filtered2oil1))
media_bomba2 <- mean(na.omit(df_filtered2oil2))
#Cores para as barras do gráfico
cores <- c("red", "black")
# Criar o gráfico de barras com as cores personalizadas
bp <- barplot(c(media_bomba1, media_bomba2),
main = "Barris de petróleo produzidos diariamente",
ylab = "Média dos barris produzidos",
xlab = "Bomba",
col = cores,
legend.text = c("Bomba1", "Bomba2"))
# Adicionar o rótulo abaixo da primeira barra
text(bp[1], par("usr")[3] - 0.2, labels = "Bomba1", pos = 1)
# Adicionar o rótulo abaixo da segunda barra
text(bp[2], par("usr")[3] - 0.2, labels = "Bomba2", pos = 1)
# Seleciona o intervalo de tempo desejado (1-6-2013 e 31-5-2014)
intervalo_dados <- subset(DADOS1, as.Date(Tempo) >= as.Date("2013-06-01") & as.Date(Tempo) <= as.Date("2014-05-31") & IC01.8)
# Calcula quantidade petróleo de cada bomba por mês
quantidade_petroleo <- intervalo_dados %>%
mutate(Mes = format(as.Date(Tempo), "%Y-%m")) %>%
group_by(Mes) %>%
summarise(Barris = sum(`IC01.8`))
#Encontrar o mês em que a Bomba 1 extraiu mais barris de petróleo
mes_max <- quantidade_petroleo$Mes[which.max(quantidade_petroleo$Barris)]
#R:A bomba 1 extraiu mais barris de petróleo em março de 2014.
set.seed(300)
#Inicializaçao das listas
bomba1_daily_prod <- c()
bomba2_daily_prod <- c()
for(i in sample(1:365,10)){
#Em cada ciclo do loop as listas auxiliares dão reset
aux1 <- c()
aux2 <- c()
#Transforma o tempo que esta em segundos em dias (e.g. 1370044800s = dia 1) e compara para encontrar os dias da amostra aleatoria e depois faz a produção diaria nesse dia e guarda no vetor
aux1<-append(aux1, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$Tempo_seg)-1370044800)/86400+1) == i,]$IC01.8))
bomba1_daily_prod<-append(bomba1_daily_prod, mean(na.omit(aux1)))
aux2<-append(aux2, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$Tempo_seg)-1370044800)/86400+1) == i,]$IC02.8))
bomba2_daily_prod<-append(bomba2_daily_prod, mean(na.omit(aux2)))
}
#Cria dataframe com a produçao diaria das duas bombas
df_daily_prod<- list(bomba1_daily_prod, bomba2_daily_prod)
#Gera o boxplot com a funçao xaxt para suprimir a impressao de valores no eixo dos x
boxplot(df_daily_prod, xaxt = "n", main = "Produção diária")
axis(1, at = c(1, 2), labels = c("Bomba 1", "Bomba 2"))
#H0: μ1 <= μ2 (a média da produção diária de petróleo da bomba 1 é menor ou igual à média da produção diária de petróleo da bomba 2)
#H1: μ1 > μ2 (a média da produção diária de petróleo da bomba 1 é maior do que a média da produção diária de petróleo da bomba 2)
#nível de significância α = 0,05
# Teste de normalidade Shapiro-Wilk para verificar se as amostras seguem uma distribuição normal
shapiro.test(bomba1_daily_prod)
shapiro.test(bomba2_daily_prod)
#Como as amostras seguem uma distribuição normal (p-value > nivel de signiicancia)  podemos fazer um teste paramétrico e vamos usar o teste t
t.test(na.omit(bomba1_daily_prod), na.omit(bomba2_daily_prod), alternative="greater", conf.level = 0.95)
#Como o p-value é menor do que o nível de significância α = 0,05, rejeitamos a hipótese nula H0 e
#concluímos que há evidência estatística para suportar a hipótese alternativa H1.
#Ou seja, a média da produção diária de petróleo da bomba 1 é maior do que a média da bomba 2 no
#período de 1-6-2013 e 31-5-2014.
#filtrar dados entre periodo determinado para avaliar qual a media de produção diária na bomba 1 e 2
bomba1_oil_rate <- as.numeric(DADOS1[as.Date(DADOS1$Tempo) >= as.Date("2013-06-01") & as.Date(DADOS1$Tempo) <= as.Date("2014-05-31"), ]$IC01.8)
bomba2_oil_rate <- as.numeric(DADOS1[as.Date(DADOS1$Tempo) >= as.Date("2013-06-01") & as.Date(DADOS1$Tempo) <= as.Date("2014-05-31"), ]$IC02.8)
#verificar a alternativa para ver se se verifica
print(mean(na.omit(bomba1_oil_rate)))
print(mean(na.omit(bomba2_oil_rate)))
print(mean(na.omit(bomba1_oil_rate))>mean(na.omit(bomba2_oil_rate)))
#Podemos verificar que na "realidade" a hipótese alternativa está correta visto que a media de produçao diária da bomba 1 é maior do que a bomba 2 no mesmo intervalo de tempo
#Tratamento de dados
library(readr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS2 <- read_csv("Dados excel/DADOS2.csv")
View(DADOS2)
#Verificamos a normalidade da distribuição dos dados,
#onde H0: distribuição normal e H1: distribuição não normal.
#Como, n<30 são feitos testes de Shapiro
shapiro.test(DADOS2$SVM) # p-value = 0.2687
shapiro.test(DADOS2$DT)  # p-value = 0.06772
shapiro.test(DADOS2$KN)  # p-value = 0.6926
shapiro.test(DADOS2$RF)  # p-value = 0.3138
shapiro.test(DADOS2$ML)  # p-value = 0.02138
shapiro.test(DADOS2$GB)  # p-value = 0.5125
#Como existe pelos menos um conjunto de dados com p-value < 0.05, o teste é não conclusivo,
#logo serão feitos testes com os coeficientes de Pearson e de Spearman
cor_matrix_pearson <- rcorr(as.matrix(DADOS2[3:8]), type = "pearson")
#As correlações lineares positivas significativas (p-value < 0.05),
cor_matrix_spearman <- rcorr(as.matrix(DADOS2[3:8]), type = "spearman")
#Nesta alínea avaliamos a Homogeneidade de variâncias e começamos por dar Melt aos dados
data_join <- melt(DADOS2[3:8], variable.name = "Type", value.name = "Precision")
#Seguimos for formular hipóteses, onde H0: existe homogeneidade entre variâncias,
#H0: existe homogeneidade entre variâncias
#H1: não existe homogeneidade entre variâncias dos grupos.
#Realizamos o teste de Levene
leveneTest(Precision ~ Type, data_join, center = mean)
#Como, p-value é inferior a 0.05, concluímos que um nível de significância de 5%, uma vez que
#rejeitamos H0, logo não podemos admitir a existência de homogeneidade entre variâncias.
#Portanto, como o teste ANOVA falha, teremos que realizar teste não paramétrico.
#c)
#Aqui efetuamos teste de Friedman já que as amostras são emparelhadas. Formulamos novamente novas
#hipóteses, em que H0 Formulação de hipóteses: não existem diferenças significativas entre a
#precisão dos algoritmos e H1: existem diferenças significativas entre a precisão dos algoritmos.
data_friedman <- data.frame(dataSet = rep(DADOS2$dsets, 6), algoritmo = c(rep(
"SVM", 10),rep("DT", 10),rep("KN",10),rep("RF", 10),rep("ML",10),rep("GB", 10)), result = c(DADOS2$SVM, DADOS2$DT, DADOS2$KN, DADOS2$RF, DADOS2$ML, DADOS2$GB))
friedman.test(result~algoritmo|dataSet, dados = data_friedman)
#Import dos dados
library(readr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS3 <- read_csv("Dados excel/DADOS3.csv")
View(DADOS3)
#Três data frames separados para cada grupo de cilindros:
dados_4cil <- subset(DADOS3, Cylinders == 4)
dados_6cil <- subset(DADOS3, Cylinders == 6)
dados_8cil <- subset(DADOS3, Cylinders == 8)
#Depois criamos um dataset onde juntamos os 3 subsets.
dataset <- c (dados_8cil, dados_6cil, dados_4cil)
groups <- factor(c(rep("Eight",length(dados_8cil)),rep("Six",length(dados_6cil)),rep("Four",length(dados_4cil))))
#h0 <- "H0: "Não há diferenças significativas entre a aceleração dos três grupos."
#h1 <- "H1: Há diferenças significativas entre a aceleração dos três grupos."
#De seguida, iremos fazer o teste de Shapiro para determinar se a amostra de dados provém de uma
#distribuição normal.
shapiro.test(DADOS3$Cylinders)
#O p-value do teste de Shapiro deu inferior a 5% logo a amostra de dados não provém de uma
#distribuição normal
#Por essa mesma razão devemos utilizar testes não paramétricos
results<- kruskal.test(dataset,groups)
#Depois temos uma if condition em que se o p-value do teste de Kruskal – Wallis for inferior a 5%
#então podemos afirmar que é lógico rejeitar H0. Se for superior a 5% então H0 não pode ser
#descartado.
alpha <- 0.05
if (any(results$p.value <= alpha)) {
print("H0 rejeitada. Pelo menos um grupo é estatisticamente diferente.")
} else {
print("H0 não rejeitada. Não há diferenças estatísticas entre os grupos.")
}
#b i) #Começamos por encontrar o modelo de regressão linear, tendo em conta que a aceleração era a
#variável dependente.
linearReg <- lm(Acceleration ~ Horsepower + Weight + Cylinders, data = DADOS3)
#Primeiro, precisamos criar um novo conjunto de dados que inclua as variáveis independentes para
#a viatura em questão:
new <- data.frame(Horsepower = 100, Weight= 2950, Cylinders = 4)
prediction <- predict(linearReg,newdata = new)
names(prediction) <- "Acceleration"
install.packages("readr")
install.packages("ggplot2")
install.packages("gtable")
install.packages("tidyr")
install.packages("dplyr")
install.packages("moments")
install.packages("Hmisc")
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(moments)
library(Hmisc)
library(reshape2)
library(car)
#Exercicio 1
#Import dos dados
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
DADOS1 <- read_csv("Dados excel/DADOS1.csv", skip = 2)
colnames(DADOS1) <- c("Tempo_seg","ESP01","ESP01.1","ESP01.2","ESP01.3","ESP01.4","ESP01.5","ESP02"
,"ESP02.1","ESP02.2","ESP02.3","ESP02.4","ESP02.5","ESP03","ESP03.1",
"ESP03.2","ESP03.3","ESP03.4","ESP03.5","IC01","IC01.1","IC01.2","IC01.3",
"IC01.4","IC01.5","IC01.6","IC01.7","IC01.8","IC02","IC02.1","IC02.2",
"IC02.3","IC02.4","IC02.5","IC02.6","IC02.7","IC02.8")
DADOS1[DADOS1 == 0] <- NA
print(DADOS1)
#Alínea a)
#Adiciona uma coluna com o tempo em formato POSIXct
str(DADOS1$Tempo_seg)
segundos <- as.numeric(DADOS1$Tempo_seg)
DADOS1$Tempo <- as.POSIXct(segundos, tz = "GMT", origin = "1970-01-01")
# visualize os dados com a nova coluna de tempo
View(DADOS1)
set.seed(300)
#Inicializaçao das listas
bomba1_daily_prod <- c()
bomba2_daily_prod <- c()
for(i in sample(1:365,10)){
#Em cada ciclo do loop as listas auxiliares dão reset
aux1 <- c()
aux2 <- c()
#Transforma o tempo que esta em segundos em dias (e.g. 1370044800s = dia 1) e compara para encontrar os dias da amostra aleatoria e depois faz a produção diaria nesse dia e guarda no vetor
aux1<-append(aux1, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$Tempo_seg)-1370044800)/86400+1) == i,]$IC01.8))
bomba1_daily_prod<-append(bomba1_daily_prod, mean(na.omit(aux1)))
aux2<-append(aux2, as.numeric(DADOS1[as.integer((as.numeric(DADOS1$Tempo_seg)-1370044800)/86400+1) == i,]$IC02.8))
bomba2_daily_prod<-append(bomba2_daily_prod, mean(na.omit(aux2)))
}
#Cria dataframe com a produçao diaria das duas bombas
df_daily_prod<- list(bomba1_daily_prod, bomba2_daily_prod)
#Gera o boxplot com a funçao xaxt para suprimir a impressao de valores no eixo dos x
boxplot(df_daily_prod, xaxt = "n", main = "Produção diária")
axis(1, at = c(1, 2), labels = c("Bomba 1", "Bomba 2"))
